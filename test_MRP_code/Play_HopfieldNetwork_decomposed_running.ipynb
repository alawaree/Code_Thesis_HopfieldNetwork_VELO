{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition of the Hopfield Network created by the MRP\n",
    "GOAL: understand what going on step by step\n",
    "\n",
    "Here they created two separate Hopfield Network, one for the track reconstruction in the odd modules and one for the track reconstruction in the even modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### DEPENDENCIES ##################################\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "import io\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi, atan, sin, sqrt, tanh, cosh, exp, ceil\n",
    "import seaborn as sns\n",
    "from numpy.core.fromnumeric import shape\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aurel\\Documents\\GitHub\\Code_Thesis_GitHub\\Code_Thesis_GitHub\n"
     ]
    }
   ],
   "source": [
    "filename = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "file_path = os.path.dirname(os.path.abspath(filename))\n",
    "project_root = os.path.dirname(file_path)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from event_model import event_model as em\n",
    "from validator import validator_lite as vl\n",
    "import data_analysis.event_generator as eg\n",
    "from visual.color_map import Colormap\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Context manager and helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CONTEXTS ##################################\n",
    "@contextlib.contextmanager\n",
    "def nostdout():\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = io.BytesIO()\n",
    "    yield\n",
    "    sys.stdout = save_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### HELPER FUNCTIONS ##################################\n",
    "def get_polar_coordinates(x, y):\n",
    "    r = math.sqrt(x ** 2 + y ** 2)\n",
    "    phi = math.atan2(x, y)\n",
    "    if phi < 0:\n",
    "        phi = math.pi - phi\n",
    "    return r, phi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save_experiment fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment(exp_name, exp_num, desc, p, event_file_name, nr_events):\n",
    "    f = open(project_root + \"/algorithms/experiments/\" + exp_name + \".txt\", \"a\")\n",
    "    f.write(\n",
    "        f\"\\nExperiment {exp_num}\\n\\n{desc}\\nNumber of events: {nr_events}\\nParameters: {p}\\n\"\n",
    "    )\n",
    "    f.close()\n",
    "    evaluate_events(\n",
    "        project_root + event_file_name,\n",
    "        p,\n",
    "        nr_events,\n",
    "        True,\n",
    "        project_root + \"/algorithms/experiments/\" + exp_name + \".txt\",\n",
    "    )\n",
    "    f = open(project_root + \"/algorithms/experiments/\" + exp_name + \".txt\", \"a\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate_events fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_events(file_name, parameters, nr_events=1, plot_event=False, output_file=None):\n",
    "\n",
    "    json_data_all_events = []\n",
    "    all_tracks = []\n",
    "    iter_even = 1\n",
    "    iter_odd = 1\n",
    "\n",
    "    all_events = [i for i in range(995)]\n",
    "    random.seed(40)\n",
    "    random.shuffle(all_events)\n",
    "    count = 0\n",
    "    j = 0\n",
    "    \n",
    "    while count < nr_events:\n",
    "        i = all_events[j]\n",
    "        j += 1\n",
    "        print(\"[INFO] Evaluate Event: %s\" % file_name + str(i))\n",
    "        size = os.path.getsize(file_name + str(i) + \".json\")\n",
    "        json_data_event, modules = load_event(\n",
    "            file_name + str(i) + \".json\", plot_event=False\n",
    "        )\n",
    "        max_neurons = 0\n",
    "        last = 0\n",
    "        for m in modules[0]:\n",
    "            n_hits = len(m.hits())\n",
    "            if last * n_hits > max_neurons:\n",
    "                max_neurons = last * n_hits\n",
    "            last = n_hits\n",
    "        last = 0\n",
    "        for m in modules[1]:\n",
    "            n_hits = len(m.hits())\n",
    "            if last * n_hits > max_neurons:\n",
    "                max_neurons = last * n_hits\n",
    "            last = n_hits\n",
    "        if max_neurons > 2200:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nstarting instance {count} out of {nr_events}\\n\")\n",
    "        start_time = time.time()\n",
    "        even_hopfield = Hopfield(modules=modules[0], parameters=parameters)\n",
    "        odd_hopfield = Hopfield(modules=modules[1], parameters=parameters)\n",
    "        end_time = time.time() - start_time\n",
    "        print(\n",
    "            \"[INFO] Hopfield Networks initialized in %i mins %.2f seconds\"\n",
    "            % (end_time // 60, end_time % 60)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            iter_even = even_hopfield.bootstrap_converge(\n",
    "                bootstraps=parameters[\"bootstrap_iters\"],\n",
    "                method=parameters[\"bootstrap_method\"],\n",
    "            )\n",
    "            iter_odd = odd_hopfield.bootstrap_converge(\n",
    "                bootstraps=parameters[\"bootstrap_iters\"],\n",
    "                method=parameters[\"bootstrap_method\"],\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            even_hopfield.mark_bifurcation()\n",
    "            odd_hopfield.mark_bifurcation()\n",
    "            even_tracks = even_hopfield.full_tracks()\n",
    "            odd_tracks = odd_hopfield.full_tracks()\n",
    "            event_tracks = even_tracks + odd_tracks\n",
    "            end_time = time.time() - start_time\n",
    "            print(\n",
    "                \"[INFO] tracks extracted in %i mins %.2f seconds\"\n",
    "                % (end_time // 60, end_time % 60)\n",
    "            )\n",
    "\n",
    "            json_data_all_events.append(json_data_event)\n",
    "            all_tracks.append(event_tracks)\n",
    "\n",
    "            if plot_event:\n",
    "                even_hopfield.plot_network_results()\n",
    "                odd_hopfield.plot_network_results()\n",
    "\n",
    "            count = count + 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    start_time = time.time()\n",
    "    if output_file:\n",
    "        print(output_file)\n",
    "        sys.stdout = open(output_file, \"a\")\n",
    "        print(f\"Average number of iterations per convergence: {(iter_even+iter_odd)/2}\")\n",
    "        vl.validate_print(json_data_all_events, all_tracks, return_data=True)\n",
    "        print(\"____________________\")\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = sys.__stdout__\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    # we could check how many tracks acutally cross the detector sides i guess to identify where some clones come from...\n",
    "    print(\n",
    "        \"[INFO] validation excecuted in %i mins %.2f seconds\"\n",
    "        % (end_time // 60, end_time % 60)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hopfield class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions about Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        ### NEURONS ###\n",
    "        \"random_neuron_init\": True,\n",
    "        \"binary_states\": False,  # try it out once maybe but scrap it\n",
    "        ### WEIGHTS ###\n",
    "        \"ALPHA\": 1,\n",
    "        \"BETA\": 10,\n",
    "        \"GAMMA\": 10,\n",
    "        \"narrowness\": 200,\n",
    "        \"constant_factor\": 0.9,\n",
    "        \"monotone_constant_factor\": 0.9,\n",
    "        #### UPDATE ###\n",
    "        \"T\": 1e-8,  # try to experiment with these rather\n",
    "        \"B\": 1e-4,  # try to experiment with these rather\n",
    "        \"T_decay\": lambda t: max(1e-8, t * 0.01),  # try to remove these\n",
    "        \"B_decay\": lambda t: max(1e-4, t * 0.04),  # try to remove these\n",
    "        \"decay_off\": False,  # using this\n",
    "        \"randomized_updates\": True,\n",
    "        \"fully_randomized_updates\": False,\n",
    "        #### THRESHOLD ###\n",
    "        \"maxActivation\": True,\n",
    "        \"THRESHOLD\": 0.2,\n",
    "        ##### CONVERGENCE ###\n",
    "        \"convergence_threshold\": 0.00000005,\n",
    "        \"bootstrap_iters\": 10,\n",
    "        \"bootstrap_method\": \"below_mean\",\n",
    "        ###### BIFURC REMOVAL #####\n",
    "        \"smart\": True,\n",
    "        \"only_weight\": False,\n",
    "        \"max_activation\": False,\n",
    "        ###### Track prunning #######\n",
    "        # here we could set the threshold\n",
    "        \"pruning_tr\": 0.01,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neurons(tracks: list = None):\n",
    "        # consider hits inbetween 2 modules as one neuron layer\n",
    "        # the neurons in N are ordered h(1,1)-h(2,1); h(1,1)-h(2,2); h(1,1)-h(2,3) etc\n",
    "        \n",
    "        if p[\"random_neuron_init\"]:\n",
    "            N = np.random.uniform(size=(modules_count - 1, max_neurons))\n",
    "        else:\n",
    "            N = np.ones(shape=(modules_count - 1, max_neurons))\n",
    "\n",
    "        if tracks:\n",
    "            N = np.zeros(shape=(modules_count - 1, max_neurons))\n",
    "            \n",
    "        for idx, nc in enumerate(neuron_count):  \n",
    "            #idx is a simple index from 0 to 34 (neuron_count is 35)\n",
    "            #nc is the value of neuronns count for that index ex: [0,1], [1,3], ..., [34,20] \n",
    "            # > in layer 0, we have 1 neurons, in layer 2, we have 3 neurons\n",
    "            N[idx, nc:] = 0\n",
    "            # this  sets the value of N matrix to zero for elements after neuron_count[idx] in each row idx of N, \n",
    "            # effectively limiting the number of neurons in each layer to the corresponding value in neuron_count[idx].\n",
    "\n",
    "\n",
    "        N_info = np.zeros(shape=(modules_count - 1, max_neurons, 4))\n",
    "        \n",
    "        for idx in range(modules_count - 1):\n",
    "            m1 = m[idx]       #first module i\n",
    "            m2 = m[idx + 1]   #second module i+1\n",
    "\n",
    "            for i, hit1 in enumerate(m1.hits()):\n",
    "                for j, hit2 in enumerate(m2.hits()):\n",
    "                    # crossing all hits i in module 1 with all hits j in module 2\n",
    "\n",
    "                    n_idx = i * hit_counts[idx + 1] + j \n",
    "                    \n",
    "                    if tracks:\n",
    "                        for t in tracks:\n",
    "                            if hit1 in t and hit2 in t:\n",
    "                                N[idx, n_idx] = 1 #activate the neuron\n",
    "                                \n",
    "                    # maybe we can check these angles again\n",
    "                    angle_xz = atan((hit2.x - hit1.x) / (hit2.z - hit1.z))\n",
    "                    angle_yz = atan((hit2.y - hit1.y) / (hit2.z - hit1.z))\n",
    "                    norm_dist = sqrt(\n",
    "                        (hit2.y - hit1.y) ** 2 + (hit2.x - hit1.x) ** 2\n",
    "                    ) / sqrt(\n",
    "                        (hit2.z - hit1.z) ** 2\n",
    "                    )  # does not work!!!\n",
    "\n",
    "                    _, r_hit1 = get_polar_coordinates(hit1.x, hit1.y)\n",
    "                    _, r_hit2 = get_polar_coordinates(hit2.x, hit2.y)\n",
    "                    monotone_dist = (r_hit2 - r_hit1) / (hit2.z - hit1.z)\n",
    "\n",
    "                    N_info[idx, n_idx, 0] = abs(angle_xz)\n",
    "                    N_info[idx, n_idx, 1] = abs(angle_yz)\n",
    "                    N_info[idx, n_idx, 2] = norm_dist  # not robust!!!!\n",
    "                    N_info[idx, n_idx, 3] = monotone_dist\n",
    "\n",
    "        return N, N_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(neg_weights=False):\n",
    "\n",
    "        ### Get parameters from the dictionnary p\n",
    "        alpha = p[\"ALPHA\"]\n",
    "        beta = p[\"BETA\"]\n",
    "        gamma = p[\"GAMMA\"]\n",
    "\n",
    "        #### Creation of the weights matrix empty\n",
    "        W = np.zeros(shape=(modules_count - 2, max_neurons, max_neurons)) \n",
    "\n",
    "        ### Filling of weights\n",
    "        for w_idx in range(modules_count - 2):  #This loop iterates w_idx over the indices of the modules, excluding the first and last modules.\n",
    "            \n",
    "            for con_idx in range(hit_counts[w_idx + 1]):  # This loop iterates con_idx over the indices of the hits in the current module.\n",
    "                \n",
    "                for i in range(hit_counts[w_idx]):  # m1\n",
    "                    ln_idx = i * hit_counts[w_idx + 1] + con_idx  # left_neuron_idx\n",
    "                    \n",
    "                    for j in range(hit_counts[w_idx + 2]):  # m3\n",
    "                        rn_idx = ( con_idx * hit_counts[w_idx + 2] + j)  # right_neuron_idx\n",
    "\n",
    "                        # Constant term from the other group\n",
    "                        constant = (N_info[w_idx, ln_idx, 2] - N_info[w_idx + 1, rn_idx, 2])\n",
    "                        constant = tanh(constant) * (p[\"narrowness\"] + 1) # tanh to force between -1 and 1\n",
    "                        constant = (-2 * constant ** 2) + 1  # this should be high if both terms are similar and low/penalizing if both are not similar\n",
    "                        constant = constant * p[\"constant_factor\"]\n",
    "                        constant = min(max(constant, - p[\"constant_factor\"]),p[\"constant_factor\"])\n",
    "\n",
    "                        # monotone constant\n",
    "                        monotone_constant = (N_info[w_idx, ln_idx, 3]- N_info[w_idx + 1, rn_idx, 3])\n",
    "                        monotone_constant = tanh(monotone_constant) * (p[\"narrowness\"] + 1)  # tanh to force between -1 and 1\n",
    "                        monotone_constant = ( -2 * monotone_constant ** 2) + 1  # this should be high if both terms are similar and low/penalizing if both are not similar\n",
    "                        monotone_constant = (monotone_constant * p[\"monotone_constant_factor\"])\n",
    "                        monotone_constant = min(max(monotone_constant, - p[\"monotone_constant_factor\"]),p[\"monotone_constant_factor\"],)\n",
    "\n",
    "                        theta = abs(\n",
    "                            N_info[w_idx, ln_idx, 0]\n",
    "                            - N_info[w_idx + 1, rn_idx, 0]\n",
    "                        )\n",
    "\n",
    "                        phi = abs(\n",
    "                            N_info[w_idx, ln_idx, 1]\n",
    "                            - N_info[w_idx + 1, rn_idx, 1]\n",
    "                        )\n",
    "\n",
    "                        W[w_idx, ln_idx, rn_idx] = (\n",
    "                            alpha\n",
    "                            * ((1 - sin(theta)) ** beta)\n",
    "                            * ((1 - sin(phi)) ** gamma)\n",
    "                            + monotone_constant\n",
    "                            + constant\n",
    "                        )\n",
    "                        #    + constant # this does not work properly\n",
    "\n",
    "                        if not neg_weights:\n",
    "                            W[w_idx, ln_idx, rn_idx] = max(\n",
    "                                0, W[w_idx, ln_idx, rn_idx]\n",
    "                            )\n",
    "        return W\n",
    "                        # maybe we can play a bit around with this\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions about network convergence\n",
    "The \"update functions\" are used to modify the N matrix containing the state of the neurons. (not the weight matrix !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    update_list = []\n",
    "    for idx in range(modules_count - 1): # for each neuron layer\n",
    "        c1 = hit_counts[idx]             # number of hits in module 1\n",
    "        c2 = hit_counts[idx + 1]         # number of hits in module 2\n",
    "        for i in range(c1 * c2):         # number of neurons created between these two module \n",
    "            update_list.append((idx, i)) # create a list of tuples with the idx of the module, and an 'id'\n",
    "                                         # for the hit, so we'll have by module a number of tuples equals \n",
    "                                         # to the number of hits in this module.hits\n",
    "\n",
    "    if p[\"randomized_updates\"]:\n",
    "        random.shuffle(update_list)\n",
    "\n",
    "    if p[\"fully_randomized_updates\"]:\n",
    "        for c in range(len(update_list)):\n",
    "            idx, i = random.sample(update_list, 1)[0]\n",
    "            update_neuron(idx, i)\n",
    "\n",
    "    else:\n",
    "        for idx, i in update_list:\n",
    "            update_neuron(idx, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_neuron(idx,i): #where idx is the layer number, and i the neuron ID\n",
    "        b = p[\"B\"]\n",
    "        t = p[\"T\"]\n",
    "        c1 = hit_counts[idx]\n",
    "        c2 = hit_counts[idx + 1]\n",
    "        update = 0\n",
    "        \n",
    "        ### PART 1 ###\n",
    "        \n",
    "        if idx > 0:                 # for all layers but not the first\n",
    "            update += N[idx - 1, :].T @ W[idx - 1, :, i] #update based on the weights of the previous module (idx-1)\n",
    "\n",
    "        if idx < modules_count - 2: # for all layers but not the two last \n",
    "            update += W[idx, i, :] @ N[idx + 1, :] #update based on the weights of this module (idx)\n",
    "            \n",
    "        if 0 < idx < modules_count - 1:  # for all layers but not the first or the last\n",
    "            update /= 2\n",
    "\n",
    "\n",
    "        ### PART 2 ###\n",
    "        # left module and right module hit id -> current neuron connects hit lm_id with hit rn_id\n",
    "        lm_id = i // c2\n",
    "        rm_id = i % c2\n",
    "\n",
    "\n",
    "        # all segments mapping to the hit in m1 -> the left module\n",
    "        m1h = np.sum(N[idx, lm_id * c2 : (lm_id + 1) * c2])\n",
    "        # all segments mapping to the hit in m2 - the right module\n",
    "        m2h = np.sum(N[idx, : c1 * c2].reshape(c2, c1)[rm_id, :])  \n",
    "\n",
    "        # we need to subtract the neuron of the segment 2 times because we add it 2 times\n",
    "        pen = m1h + m2h - 2 * N[idx, i]\n",
    "\n",
    "        _update = 0.5 * (1 + tanh(update / t - b * pen / t))\n",
    "\n",
    "        if p[\"binary_states\"]:\n",
    "            # NB: usually never use binay states\n",
    "            if random.random() < _update:\n",
    "                N[idx, i] = 1\n",
    "            else:\n",
    "                N[idx, i] = 0\n",
    "        else:\n",
    "            N[idx, i] = _update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy():\n",
    "        b = p[\"B\"]\n",
    "\n",
    "        E = 0\n",
    "        bifurc_pen = 0\n",
    "        for idx in range(modules_count - 2):\n",
    "            c1 = hit_counts[idx]\n",
    "            c2 = hit_counts[idx + 1]\n",
    "            c3 = hit_counts[idx + 2]\n",
    "\n",
    "            f1 = 0.5\n",
    "            f2 = 0.5\n",
    "            if idx == 0:\n",
    "                f1 = 1\n",
    "            if idx == modules_count - 3:\n",
    "                f2 = 1\n",
    "            N1_pen = N[idx, : c1 * c2].reshape(c2, c1)\n",
    "            N2_pen = N[idx + 1, : c2 * c3].reshape(c2, c3)\n",
    "            bifurc_pen = (\n",
    "                np.sum(np.trace(N1_pen @ N1_pen.T)) * f1\n",
    "                + np.sum(np.trace(N2_pen @ N2_pen.T)) * f2\n",
    "                - np.sum(N[idx, :] * N[idx, :]) * f1\n",
    "                - np.sum(N[idx + 1, :] * N[idx + 1, :]) * f2\n",
    "            )\n",
    "\n",
    "            E += (\n",
    "                -0.5 * (N[idx, :].T @ W[idx, :, :] @ N[idx + 1, :])\n",
    "                + b * bifurc_pen\n",
    "            )\n",
    "        return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converge():\n",
    "        # Basically keep updating until the difference in Energy between timesteps is lower than 0.0005 (Based on Stimfple-Abele)\n",
    "        # Passaleva uses a different kind of convergence i think (4)\n",
    "        energies = [energy()]\n",
    "          # store all energies (not fastest but maybe nice for visualisations)\n",
    "        t = 0  # timesteps\n",
    "\n",
    "        p[\"T\"] = start_T\n",
    "        # self.p[\"B\"] = self.start_B\n",
    "        # print(f\"N at iteration{t}:\", np.round(my_instance.N, 1))\n",
    "        update()\n",
    "        t += 1\n",
    "        energies.append(energy())\n",
    "\n",
    "        while (abs(abs(energies[-2]) - abs(energies[-1]))>= p[\"convergence_threshold\"]):\n",
    "            update()\n",
    "            energies.append(energy())\n",
    "            # print(f\"N at iteration{t}:\", np.round(my_instance.N, 1))\n",
    "            t += 1\n",
    "            if not p[\"decay_off\"]:\n",
    "                p[\"T\"] = p[\"T_decay\"](p[\"T\"])\n",
    "                p[\"B\"] = p[\"B_decay\"](t)\n",
    "            else:\n",
    "                pass  # keep T and B fixed\n",
    "\n",
    "        # print(\"Network Converged after \" + str(t) + \" steps\")\n",
    "        # print(\"Energy = \" + str(self.energies[-1]))\n",
    "        return N, energies[-1], t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_converge(bootstraps=50, method=\"below_mean\"):\n",
    "        start_time = time.time()\n",
    "        states_list = []\n",
    "        energy_list = []\n",
    "        iter_list = []\n",
    "\n",
    "        for i in range(bootstraps):\n",
    "\n",
    "            if p[\"random_neuron_init\"]:\n",
    "                # We only need to reinitialize if we randomly initialize\n",
    "                init_neurons()\n",
    "\n",
    "            states, energy, iters = converge()\n",
    "            print(\"energy: \" + str(energy))\n",
    "\n",
    "            states_list.append(states)\n",
    "            energy_list.append(energy)\n",
    "            iter_list.append(iters)\n",
    "            # print(f\"Finished {i+1}/{bootstraps} iterations\")\n",
    "\n",
    "        if method == \"minimum\":\n",
    "            # eventually we could take the lowest 20% or so\n",
    "            N = states_list[np.argmax(energy_list)]\n",
    "            energy_list = [np.amax(energy_list)]\n",
    "\n",
    "        elif method == \"below_median\":\n",
    "            median = np.median(energy_list)\n",
    "            _tmp_states = []\n",
    "            for states, e in zip(states_list, energy_list):\n",
    "                if e <= median:\n",
    "                    _tmp_states.append(states)\n",
    "            _tmp_states = np.stack(_tmp_states, axis=2)\n",
    "            N = np.mean(_tmp_states, axis=2)\n",
    "\n",
    "        elif method == \"below_mean\":\n",
    "            mean = np.mean(energy_list)\n",
    "            _tmp_states = []\n",
    "            for states, e in zip(states_list, energy_list):\n",
    "                if e <= mean:\n",
    "                    _tmp_states.append(states)\n",
    "            _tmp_states = np.stack(_tmp_states, axis=2)\n",
    "            N = np.mean(_tmp_states, axis=2)\n",
    "            \n",
    "        else:\n",
    "            stacked_states = np.stack(states_list, axis=2)\n",
    "            N = np.mean(stacked_states, axis=2)\n",
    "\n",
    "\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        print(\n",
    "            \"[HOPFIELD] converged network by %s after %i mins %.2f seconds; (energy: %.2f)\"\n",
    "            % (method, end_time // 60, end_time % 60, np.mean(energy_list))\n",
    "        )\n",
    "        return sum(iter_list) / len(iter_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions about obtaining the final tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracks():\n",
    "# What the papers say:  The answer is given by the final set of active Neurons.\n",
    "# Idea: All sets of Neurons connected together are considered as track candidates.\n",
    "# Code idea: All neurons that share a hit and are both activated are track candidates.\n",
    "\n",
    "    global_candidates = []\n",
    "    global_candidate_states = []\n",
    "\n",
    "    for idx in range(modules_count - 2): #for each layer of the network but the last one\n",
    "            candidates = []\n",
    "            candidate_states = []\n",
    "            \n",
    "            l1 = hit_counts[idx]     # number of hits in module 1\n",
    "            l2 = hit_counts[idx + 1] # number of hits in module 2\n",
    "            l3 = hit_counts[idx + 2] # number of hits in module 3\n",
    "\n",
    "            if p[\"maxActivation\"]:\n",
    "                candidates = []\n",
    "                thresh = p[\"THRESHOLD\"]\n",
    "\n",
    "                n1_transform = N[idx, : l2 * l1].reshape(l1, l2).T.copy()       # select the row of the layer idx in the N matrix and the first l2*l1 element (the number of neurons/segments created between module 1 and module 2)\n",
    "                n2_transform = N[idx + 1, : l3 * l2].reshape(l2, l3).T.copy()   # select the row of the layer idx+1 in the N matrix and the first l3*l2 element (the number of neurons/segments created between module 2 and module 3)\n",
    "                \n",
    "                for con in range(l2):  # loop over the \"connection hits\" in module 2\n",
    "                    \n",
    "                    h1_idx = np.argmax(n1_transform[con, :]) #index of the neuron/semgent with maximum activation value in the 'conth' row of n1_transform > select of the left neuron/segment for the conth hit in module 2\n",
    "                    h3_idx = np.argmax(n2_transform[:, con]) #index of the neuron/segment with maximum activation value in the 'conth' column of n2_transform > select of the right neuron/segment for the conth hit in module 2\n",
    "\n",
    "                    if (n1_transform[con, h1_idx] < thresh or n2_transform[h3_idx, con] < thresh): \n",
    "                        continue #skip this if the value are too low\n",
    "\n",
    "                    hit1 = m[idx].hits()[h1_idx]     #retrieve the info of the hit in m1 which is the left hit of the segment h1_idx\n",
    "                    hit2 = m[idx + 1].hits()[con]    #retrieve the info of the hit in m2 'con' (right hit of h1_idx, left hit of h3_idx)\n",
    "                    hit3 = m[idx + 2].hits()[h3_idx] #retrieve the info of the hit in m3 which is the right hit of the segment h3_idx\n",
    "\n",
    "                    candidates.append(em.track([hit1, hit2, hit3])) #created a track candidate with the concerned hits\n",
    "                    extracted_hits.add(hit1) #add the concerned hits\n",
    "                    extracted_hits.add(hit2)\n",
    "                    extracted_hits.add(hit3)\n",
    "\n",
    "                    # storage of the states of neurons concerned by the tracks\n",
    "                    candidate_states.append(n1_transform[con, h1_idx]) \n",
    "                    candidate_states.append(n2_transform[h3_idx, con])\n",
    "\n",
    "\n",
    "            global_candidates += candidates\n",
    "            global_candidate_states += candidate_states\n",
    "\n",
    "    extracted_tracks = global_candidates\n",
    "    extracted_track_states = global_candidate_states\n",
    "\n",
    "    return global_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tracks(tracks, track_infos):\n",
    "        tr = p[\"pruning_tr\"]\n",
    "        out_tracks = []\n",
    "        \n",
    "        for track, info in zip(tracks, track_infos): #for each track candidates\n",
    "            num_hits = len(track) #total number of hits by tracks\n",
    "            if num_hits < 3:      #discard the track candidate that are too small\n",
    "                continue\n",
    "\n",
    "            cand = [track[0], track[1]]  #temporary list containing the first two segments in the track candidate\n",
    "            cand_info = info[0]          #variable contaning additional info associated with the first segment in the track\n",
    "\n",
    "            for idx in range(1, num_hits - 1): #loops through the remaining segments in the track candidate \n",
    "            # and checks if the difference between the additional information for the current segment and \n",
    "            # the previous segment is below a pruning threshold (reminder: angles info are stored in there)\n",
    "\n",
    "                if sum(abs(cand_info - info[idx])) < tr:\n",
    "                    cand = cand + [track[idx + 1]]  #the current segment is added to the cand list\n",
    "                    \n",
    "                else:\n",
    "                    if len(cand) > 2: #i.e. another segment has been added before in the loop because the tr was small\n",
    "                        out_tracks = out_tracks + [cand]  #the cand list is added to the out_tracks list, which is a list of pruned track candidates.\n",
    "                    cand = [track[idx], track[idx + 1]]   #let's go the the next track\n",
    "                cand_info = info[idx] #let's go to the next track\n",
    "\n",
    "            if len(cand) > 2: #the cand list is added to the out_tracks list, which is a list of pruned track candidates.\n",
    "                out_tracks = out_tracks + [cand]\n",
    "                \n",
    "        return out_tracks #NB: out_tracks = tracks kept in the final solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_tracks():\n",
    "        # this will deal with stange angles!!!\n",
    "        # under the assumption that we removed bifuration completely\n",
    "        # init this active tracks with all active neurons in layer 1! -> key is the right hit\n",
    "\n",
    "        global_candidates = []\n",
    "        global_candidate_states = []\n",
    "        global_candidate_info = []\n",
    "        tracks = {}\n",
    " \n",
    "        # Operates in two nested loops over the number of modules and number of hits in each module.\n",
    "        for idx in range(modules_count - 1): #for each layer\n",
    "\n",
    "            tracks_2 = {}\n",
    "            l1 = hit_counts[idx]      # number of hits in module 1 / Left module\n",
    "            l2 = hit_counts[idx + 1]  # number of hits in module 2 / Right module\n",
    "\n",
    "            tr = p[\"THRESHOLD\"]\n",
    "\n",
    "            for segment in range(l1 * l2): #for each neuron/segment in the layer idx\n",
    "\n",
    "                if N[idx, segment] < tr:    # neurons states matrix\n",
    "                    continue                # if the activation value is too low, then don't even consider this segment as a candidate\n",
    "                \n",
    "                l_hit = m[idx].hits()[segment // l2]\n",
    "                r_hit = m[idx + 1].hits()[segment % l2] \n",
    "                #> it work well to create all combinations of hits inbetween the two modules so all segments possible (same as inside of the function update_neurons())\n",
    "\n",
    "                ### IF CONTINUING A TRACK ####\n",
    "                if l_hit in tracks.keys():   #useful once the function has already loop several times, check if the left hit is already in the track dictionary,\n",
    "                #as we start the track from left to right, the right hit of the track i could become the left hit of the track i+1\n",
    "\n",
    "                    (track, states, angle) = tracks[l_hit]\n",
    "\n",
    "                    track = track + [r_hit]                     #save a new track by adding the right hit ot the existing track\n",
    "                    states = states + [N[idx, segment]]         #add the state of the new segment added to the list of segments states already in the track\n",
    "                    info = angle + [N_info[idx, segment, :]]    #add the info of the new segment added to the list of segments info already in the track\n",
    "                    del tracks[l_hit]                           #deleted the previous track as a new one has been created on top of it\n",
    "\n",
    "                    extracted_hits.add(r_hit) \n",
    "                    tracks_2[r_hit] = (track, states, info)\n",
    "                \n",
    "                ### IF STARTING A NEW TRACK ####\n",
    "                else: # i.e. the left hit is not already used in track before\n",
    "                    \n",
    "                    track = [l_hit, r_hit]            #save a new track with the left and right hit (only 1 segment in there)\n",
    "                    states = [N[idx, segment]]        #save the activation value of the segment considered as track \n",
    "                    info = [N_info[idx, segment, :]]  #save the angle information of the segment considered as track\n",
    "\n",
    "                    tracks_2[r_hit] = (track, states, info) #add the right hit to the tracks_2 dictionnary with the new informations > we go from the left to the right of the detector \n",
    "                    extracted_hits.add(r_hit)               #add the right hit to the extracted hits set\n",
    "                    extracted_hits.add(l_hit)               #add the left hit to the extracted hits set\n",
    "\n",
    "            for _, value in tracks.items():\n",
    "                (track, states, info) = value\n",
    "                global_candidates = global_candidates + [track]\n",
    "                global_candidate_states = global_candidate_states + [states]\n",
    "                global_candidate_info = global_candidate_info + [info]\n",
    "            tracks = tracks_2\n",
    "\n",
    "        for _, value in tracks.items():\n",
    "            (track, states, info) = value\n",
    "            global_candidates = global_candidates + [track]\n",
    "            global_candidate_states = global_candidate_states + [states]\n",
    "            global_candidate_info = global_candidate_info + [info]\n",
    "\n",
    "        # here comes the function of 'pruning...' maybe i need to store more info for doing that!!!\n",
    "        global_candidates = prune_tracks(global_candidates, global_candidate_info)\n",
    "\n",
    "        global_candidates = [em.track(hits) for hits in global_candidates] # pruned track candidates are then passed through the em.track() function in full_tracks() to produce a list of final extracted tracks\n",
    "        extracted_tracks = global_candidates\n",
    "        extracted_track_states = global_candidate_states\n",
    "\n",
    "        return global_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_bifurcation():\n",
    "        zero = True\n",
    "        max_activation = p[\"max_activation\"]\n",
    "        smart = p[\"smart\"]\n",
    "\n",
    "        if max_activation:\n",
    "            zero = False\n",
    "\n",
    "        if smart:\n",
    "            zero = False\n",
    "            max_activation = False\n",
    "\n",
    "        tr = p[\"THRESHOLD\"]\n",
    "        N[N <= tr] = 0 # All neurons states values that are less than or equal the treshold are set to 0.\n",
    "\n",
    "        ## General idea of search for bifurcation neurons:\n",
    "        # STEP 1: we visit all neurons in one layer and keep going onl with neurons where the activation (state value) is bigger than the treshold\n",
    "        # STEP 2: we check all neurons for activation and check the ones higher than the treshold\n",
    "        # STEP 3: for each segment we look wether there is bifurcation on the left or right hit\n",
    "        # STEP 4: we keep the segment with the highest activation value, put its value to 1 and the activation value of the others segments concerned by the bifurcation to 0\n",
    "\n",
    "\n",
    "        for idx in range(modules_count - 1): # for each layer of the network\n",
    "\n",
    "            #STEP 1\n",
    "            c1 = hit_counts[idx]       #number of hits in module 1\n",
    "            c2 = hit_counts[idx + 1]   #number of hits in module 2\n",
    "\n",
    "            for segment in range(c1 * c2): # loop through all possible segments/neurons in layer 1 (number = c1*c2, all hits combinations tested)\n",
    "                \n",
    "                # STEP 2\n",
    "                if N[idx, segment] < tr:   # if neuron state value is under the threshold don't consider this neuron\n",
    "                    continue\n",
    "                \n",
    "                r_hit = segment % c2  # ID of the right hit of the segment      (NB: idx is the same so no need to precise from here)\n",
    "                l_hit = segment // c2 # ID of the left hit of the segment       (NB: idx is the same so no need to precise from here)\n",
    "\n",
    "                # STEP 3\n",
    "\n",
    "                # A. LEFT-RIGHT BIFURCATION (for each pair of left and right hits)\n",
    "\n",
    "                activation_mask = N[idx, : c1 * c2].reshape(c1, c2)[:, r_hit] > tr   \n",
    "                # Idea: creation of an activation mask to identify the activated neurons (segments) in the current layer that are connected to a specific neuron (segment) in the next layer, i.e. a neuron using the r_hit\n",
    "\n",
    "                # Shape: reshaping the row corresponding to the current neuron/segment in the weight matrix N into a 2D array of shape (c1, c2) (with c1 rows and c2 columns in the 2D weight matrix for the current layer) \n",
    "                # and then selecting the column corresponding to the next neuron in the weight matrix.\n",
    "                # Operation: this activation_mask is a 1D Boolean array of length c1 (#hits in the left-module) where each element i is True\n",
    "                # if the i-th neuron (segment) in the current layer (idx) is activated (i.e. higher than treshold) and is connected to the next neuron (segment) specified by the segment variable\n",
    "\n",
    "                if sum(activation_mask) > 1:  # we have at least 1 bifurcation into the right hit\n",
    "\n",
    "                    affected_neurons = []\n",
    "                    for i in range(c1):  # loop over all nerons affected by the bifurcation\n",
    "                        if activation_mask[i]:\n",
    "                            if zero: #condition precised at the start (NB: I think zero is always false ...)\n",
    "                                N[idx, (i * c2) + r_hit] = 0 #the state of the affected segments set to 0\n",
    "                            else:\n",
    "                                affected_neurons = affected_neurons + [(i * c2) + r_hit] # we obtain a list with each element looking like [ID of the segment in this layer + ID of the right hits of the segment]\n",
    "\n",
    "                    # METHOD 1\n",
    "                    if smart:\n",
    "                        # Simple rule: when a bifurcation is detected on right side, we look next active neurons going out\n",
    "                        # and promote the ones where the weight is high (angle diff is low) if next neuron layer exist\n",
    "\n",
    "                        if idx < modules_count - 2:  # can check to the right, i.e. there is a next neuron layer on the right\n",
    "\n",
    "                            c3 = hit_counts[idx + 2] # hits in module 3\n",
    "\n",
    "                            activation_mask_2 = (N[idx + 1, : c2 * c3].reshape(c2, c3)[r_hit, :] > tr) \n",
    "                            # Idea: creation of an activation mask to identify the activated neurons (segments) in the current layer that are connected to a specific neuron (segment) in the next layer, \n",
    "                            # i.e. a neuron using the r_hit\n",
    "\n",
    "                            # Same idea but length c2 and element is True if the i-th neuron (segment) in the next layer (idx+1) is activated (i.e. higher than treshold) and is connected to the next neuron (segment)\n",
    "\n",
    "                            affected_neurons_2 = []\n",
    "                            for i in range(c3):  # loop over all nerons affected by bifurcation\n",
    "                                if activation_mask_2[i]:\n",
    "                                    affected_neurons_2 = affected_neurons_2 + [c3 * r_hit + i]\n",
    "\n",
    "                            if len(affected_neurons_2) > 0: \n",
    "                                max_val = 0\n",
    "                                max_l = None\n",
    "                                max_r = None\n",
    "\n",
    "                                for e in affected_neurons: # list of ID neuron/segment in layer idx using the r_hit \n",
    "                                    for j in affected_neurons_2: # list of ID neuron/segment in layer idx+1 also using the r_hit (but as a left hit lmao)\n",
    "                                        \n",
    "                                        c = (N[idx, e] * W[idx, e, j]* N[idx + 1, j]) # new calculated weight \n",
    "\n",
    "                                        if p[\"only_weight\"]:\n",
    "                                            c = W[idx, e, j] #using the new calculated weight \n",
    "\n",
    "                                        if c > max_val: #if this new calculated weight is the higher for all j segment of layer idx+1, then ...\n",
    "                                            max_l = e #Index in affected neuron\n",
    "                                            max_r = j #Index in afftected neurons 2\n",
    "                                            max_val = c #new weight\n",
    "                                            \n",
    "                                    # a max_l, max_r, max_val are calculated for each loop\n",
    "\n",
    "                                    N[idx, e] = 0 # state of neuron/segment e of layer idx set up to 0\n",
    "                                                                        \n",
    "\n",
    "                                for j in affected_neurons_2:\n",
    "                                    N[idx + 1, j] = 0 # state of neuron/segment j of layer idx+1 set up to 0\n",
    "\n",
    "                                #All \"concerned\" neurons/segments have their weight put back to 0 \n",
    "                                \n",
    "                                if max_r is not None and max_l is not None: #i.e. if a pairs of segment has distinguished itself\n",
    "                                    N[idx, max_l] = 1       #weight of the neuron/segment in idx that obtained the max value c\n",
    "                                    N[idx + 1, max_r] = 1   #weight of the neuron/segment in idx+1 that obtained the max value c\n",
    "\n",
    "\n",
    "                            else: #if the right hit is not used as a left hit for some segments in the next layer (i.e no bifurcation in the next module)\n",
    "                                max_activation = True\n",
    "\n",
    "                        else: #if it's the last layer\n",
    "                            max_activation = True\n",
    "                    \n",
    "\n",
    "                    # METHOD 2: the method sets the activation state of the neuron with the highest activation value to 1.\n",
    "                    if max_activation:\n",
    "                        max_activation = N[idx, affected_neurons[0]] #variable created to obtain the activation values of the neurons in layer idx affected by bifuraction\n",
    "                        max_id = affected_neurons[0]                 #variable created to keep the ID of neurons with highest activation value\n",
    "                        \n",
    "                        for e in affected_neurons: #for segment affected by the bifurcation\n",
    "                            if N[idx, e] >= max_activation:\n",
    "                                max_id = e\n",
    "                                max_activation = N[idx, e]\n",
    "\n",
    "                            N[idx, e] = 0 # put the activation values of all concerned neurons to 0\n",
    "\n",
    "                        N[idx, max_id] = 1 # excpect for the one with the highest max activation value that will be set to 1\n",
    "\n",
    "                    if smart:\n",
    "                        max_activation = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # right-left bifurcation\n",
    "                activation_mask = N[idx, : c1 * c2].reshape(c1, c2)[l_hit, :] > tr\n",
    "                if sum(activation_mask) > 1:\n",
    "                    affected_neurons = []\n",
    "                    affected_neurons_2 = []\n",
    "                    for i in range(c2):\n",
    "                        if activation_mask[i]:\n",
    "                            if zero:\n",
    "                                N[idx, (l_hit * c2) + i] = 0\n",
    "                            else:\n",
    "                                affected_neurons = affected_neurons + [(l_hit * c2) + i]\n",
    "                    if smart:  # i know there can be only one neuron on the right.\n",
    "                        if idx > 0:\n",
    "                            # can check here only for the first active neuron, because we removed\n",
    "                            # the other bifurcation in the previous iteration\n",
    "                            c0 = hit_counts[idx - 1]\n",
    "                            activation_mask_2 = (\n",
    "                                N[idx - 1, : c0 * c1].reshape(c0, c1)[:, l_hit]\n",
    "                                > tr\n",
    "                            )\n",
    "                            if sum(activation_mask_2) > 0:\n",
    "                                for i in range(\n",
    "                                    c0  # this was c0...\n",
    "                                ):  # loop over all nerons affected by bifurc\n",
    "                                    if activation_mask_2[i]:\n",
    "                                        affected_neurons_2 = affected_neurons_2 + [\n",
    "                                            c1 * i + l_hit\n",
    "                                        ]\n",
    "\n",
    "                                if len(affected_neurons_2) > 0:\n",
    "                                    max_val = 0\n",
    "                                    max_l = None\n",
    "                                    max_r = None\n",
    "                                    for e in affected_neurons_2:\n",
    "                                        for j in affected_neurons:\n",
    "                                            c = (\n",
    "                                                N[idx - 1, e]\n",
    "                                                * W[idx - 1, e, j]\n",
    "                                                * N[idx, j]\n",
    "                                            )\n",
    "                                            if p[\"only_weight\"]:\n",
    "                                                c = W[idx - 1, e, j]\n",
    "                                            if c > max_val:\n",
    "                                                max_l = e\n",
    "                                                max_r = j\n",
    "                                                max_val = c\n",
    "                                        N[idx - 1, e] = 0\n",
    "                                for e in affected_neurons:\n",
    "                                    N[idx, j] = 0\n",
    "                                if max_r is not None and max_l is not None:\n",
    "                                    N[idx - 1, max_l] = 1\n",
    "                                    N[idx, max_r] = 1\n",
    "                            else:\n",
    "                                max_activation = True\n",
    "                        else:\n",
    "                            max_activation = True\n",
    "                        pass\n",
    "\n",
    "                    if max_activation:\n",
    "                        # check to the left or max score\n",
    "                        max_activation = N[idx, affected_neurons[0]]\n",
    "                        max_id = affected_neurons[0]\n",
    "                        for e in affected_neurons:\n",
    "                            if N[idx, e] >= max_activation:\n",
    "                                max_id = e\n",
    "                                max_activation = N[idx, e]\n",
    "                            N[idx, e] = 0\n",
    "                        N[idx, max_id] = 1\n",
    "\n",
    "        # converged, averaged neuron state\n",
    "        # what do we want to do -> search all neurons wether there is bifurcation\n",
    "        # how to search this, by the indices... and then we store it as a combination of hit id_s, and which side of this element the bifurcation occurs\n",
    "        # bifiurcation is stored as a list of hit ids, with\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions about plotting the final tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_tracks(threshold=None, show_states=False):\n",
    "        # Creates a colormap from blue to red for small to large values respectively\n",
    "        c_map = Colormap(0, 1, 2 / 3.0, 0)\n",
    "        c = []\n",
    "        tracks = []\n",
    "        for idx in range(modules_count - 1):\n",
    "            m1 = m[idx]\n",
    "            m2 = m[idx + 1]\n",
    "\n",
    "            for i, hit1 in enumerate(m1.hits()):\n",
    "                for j, hit2 in enumerate(m2.hits()):\n",
    "                    n_idx = i * hit_counts[idx + 1] + j\n",
    "                    if threshold:\n",
    "                        if N[idx, n_idx] >= threshold:\n",
    "                            tracks.append(em.track([hit1, hit2]))\n",
    "                            if show_states:\n",
    "                                c.append(c_map.get_color_rgb(N[idx, n_idx]))\n",
    "                        continue\n",
    "                    if show_states:\n",
    "                        c.append(c_map.get_color_rgb(N[idx, n_idx]))\n",
    "                    tracks.append(em.track([hit1, hit2]))\n",
    "        eg.plot_tracks_and_modules(tracks, m, colors=c)\n",
    "\n",
    "def tracks_with_hit(hit):\n",
    "        return [track for track in extracted_tracks if hit in track.hits]\n",
    "\n",
    "def print_neurons():\n",
    "        n = len(N)\n",
    "        for i in range(n):\n",
    "            m = int(sqrt(len(N[i])))\n",
    "            for j in range(m):\n",
    "                print(f\"m{i+1}h{j+1}: {N[i, (j*m):((j+1)*m)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_results(show_states=False):\n",
    "        if show_states:\n",
    "            # Creates a colormap from blue to red for small to large values respectively\n",
    "            c_map = Colormap(0, 1, 2 / 3.0, 0)\n",
    "            colors = []\n",
    "            [colors.append(c_map.get_color_rgb(v)) for v in extracted_track_states]\n",
    "            eg.plot_tracks_and_modules(\n",
    "                extracted_tracks,\n",
    "                m,\n",
    "                colors=colors,\n",
    "                title=\"Hopfield Output with states\",\n",
    "            )\n",
    "        else:\n",
    "            eg.plot_tracks_and_modules(\n",
    "                extracted_tracks, m, title=\"Hopfield Output\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event(file_name, plot_event=False):\n",
    "    f = open(file_name)\n",
    "    json_data_event = json.loads(f.read())\n",
    "\n",
    "    ev = em.event(json_data_event, read_tracks=True)\n",
    "\n",
    "    modules = ev.modules\n",
    "    tracks = ev.real_tracks\n",
    "\n",
    "    if plot_event:\n",
    "        eg.plot_tracks_and_modules(tracks, modules, title=\"Loaded Event\")\n",
    "\n",
    "    modules_even = []\n",
    "    modules_odd = []\n",
    "\n",
    "    for i in range(len(modules)):\n",
    "        if i % 2 == 0:\n",
    "            modules_even.append(modules[i])\n",
    "        else:\n",
    "            modules_odd.append(modules[i])\n",
    "\n",
    "    return json_data_event, (modules_even, modules_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hopfield_init(modules: list, parameters: dict, tracks: list = None):\n",
    "    p = parameters\n",
    "    m = modules\n",
    "    start_T = p[\"T\"]\n",
    "    start_B = p[\"B\"]\n",
    "    N = None\n",
    "    N_info = None\n",
    "    modules_count = len(modules)\n",
    "    hit_counts = [len(module.hits()) for module in m]\n",
    "    neuron_count = [\n",
    "        hit_counts[i] * hit_counts[i + 1]\n",
    "        for i in range(modules_count - 1)\n",
    "        ]\n",
    "    flips = 0\n",
    "    max_neurons = max(neuron_count)\n",
    "    init_neurons(tracks=tracks)\n",
    "    init_weights()\n",
    "    extracted_hits = set()\n",
    "    extracted_tracks = []\n",
    "    extracted_track_states = []\n",
    "    energies = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluate Event: c:\\Users\\aurel\\Documents\\GitHub\\Code_Thesis_GitHub\\Code_Thesis_GitHub/datasets/minibias/velo_event_3\n"
     ]
    }
   ],
   "source": [
    "# EVALUTE EVENT FOR 1 EVENT WHERE WE CAN TRACK WHAT'S GOING ON\n",
    "\n",
    "i = 3\n",
    "event_file_name = \"/datasets/minibias/velo_event_\"\n",
    "file_name = project_root + event_file_name\n",
    "nr_events=1\n",
    "plot_event=False\n",
    "\n",
    "json_data_all_events = []\n",
    "all_tracks = []\n",
    "iter_even = 1\n",
    "iter_odd = 1\n",
    "\n",
    "nr_max_neurons_tracking = []\n",
    "id_events_tracking = []\n",
    "total_hits_tracking = []\n",
    "timing_tracking = []\n",
    "start_time_networks = time.time() \n",
    "\n",
    "print(\"[INFO] Evaluate Event: %s\" % file_name + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting instance 1 out of 1\n",
      "\n",
      "Number of total hits: 3172\n",
      "Number of max neurons: 7832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### NETWORK INITIALIZATION (Activation states and weights matrices)\n",
    "\n",
    "# STEP 1\n",
    "\n",
    "start_timing = time.time() \n",
    "json_data_event, modules = load_event(file_name + str(i) + \".json\", plot_event=False)\n",
    "            \n",
    "total_hits = 0\n",
    "max_neurons = 0\n",
    "last = 0\n",
    "\n",
    "for m in modules[0]:\n",
    "    n_hits = len(m.hits())\n",
    "    if last * n_hits > max_neurons:\n",
    "            max_neurons = last * n_hits\n",
    "    last = n_hits\n",
    "    total_hits = total_hits + n_hits\n",
    "            \n",
    "last = 0\n",
    "for m in modules[1]:\n",
    "    n_hits = len(m.hits())\n",
    "    if last * n_hits > max_neurons:\n",
    "        max_neurons = last * n_hits\n",
    "    last = n_hits\n",
    "    total_hits = total_hits + n_hits\n",
    "\n",
    "\n",
    "nr_max_neurons_tracking.append(max_neurons)\n",
    "total_hits_tracking.append(total_hits)\n",
    "id_events_tracking.append(i)\n",
    "\n",
    "\n",
    "print(f\"\\nStarting instance {1} out of {nr_events}\\n\")\n",
    "print(f'Number of total hits: {total_hits}')\n",
    "print(f'Number of max neurons: {max_neurons}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Hopfield Networks initialized in 0 mins 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# STEP 2\n",
    "\n",
    "start_time = time.time()\n",
    "even_hopfield = Hopfield_init(modules=modules[0], parameters=parameters)\n",
    "odd_hopfield = Hopfield_init(modules=modules[1], parameters=parameters)\n",
    "end_time = time.time() - start_time\n",
    "            \n",
    "print(\"[INFO] Hopfield Networks initialized in %i mins %.2f seconds\"\n",
    "        % (end_time // 60, end_time % 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e13a6a7dce0aae7412225c345a3011e4be0b7b46c112ebb5d87e91cc76b9a7f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
